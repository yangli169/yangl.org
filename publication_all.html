         <div style="float: left; clear: left; width: 100%; margin: 1em 0 1em 0"> 
		   	
			 <div class="sectiontitle">
				Publications [
				<u>All</u>&nbsp;&middot;&nbsp;
				HCI&nbsp;&middot;&nbsp;
				Deep Learning]
				<!--<a href="http://www.youtube.com/user/yangli169/videos?flow=grid&view=0">Videos</a> -->
			 </div>
			 
			 <div class="year">
				2019
			 </div>
			 
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="https://arxiv.org/abs/1905.07953"><img src="images/cluster-gcn.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="https://arxiv.org/abs/1905.07953">Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh.<span>
					<span class="conference">Accepted to <a href="https://www.kdd.org/kdd2019/">KDD'19 Research Track ORAL</a>, <a href="https://arxiv.org/abs/1905.07953">arXiv:1905.07953 [cs.LG]</a></span>
				  </p>
				  <span class="contribution">A method for training deep and large-scale GCN by cluster-based sub-graph batching.
		     </div> 
		     <!-- end of an item -->
			 
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="https://arxiv.org/abs/1811.11205"><img src="images/gaternet.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="https://arxiv.org/abs/1811.11205">You Look Twice: GaterNet for Dynamic Filter Selection in CNNs</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Zhourong Chen, Yang Li, Samy Bengio, Si Si.<span>
					<span class="conference">To Appear at <a href="http://cvpr2019.thecvf.com">CVPR'19</a>, <a href="https://arxiv.org/abs/1811.11205">arXiv:1811.11205 [cs.LG]</a></span>
				  </p>
				  <span class="contribution">An architecture for input-dependent dynamic filter selection in deep convolutional neural networks.
		     </div> 
		     <!-- end of an item -->
			 
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="https://arxiv.org/abs/1810.10126"><img src="images/area_attention.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="https://arxiv.org/abs/1810.10126">Area Attention</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Lukasz Kaiser, Samy Bengio, Si Si.<span>
				    <span class="conference">Accepted to ICML'19, <a href="https://arxiv.org/abs/1810.10126">arXiv:1810.10126 [cs.LG]</a></span>
				  </p>
				  <span class="contribution">An attentional mechanism that allows a model to attend to information with varying granularity.
		     </div> 
		     <!-- end of an item -->
			 
   			<!-- start of an item -->
   		     <div style="clear: left; margin: 0 0 1em 0" id="doppio">
   				<!-- thumbnail -->
   				  <a href="https://arxiv.org/abs/1902.11247"><img src="images/tappability.gif" class="thumbnail"/></a>
   				  <p class="ptitle">
   				    <a href="https://arxiv.org/abs/1902.11247">Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning</a>
   				  </p>
   				  <p style="margin: 0 0 0.2em 0">
   				    <span class="author">Amanda Swearngin, Yang Li.<span>
   				    <span class="conference">To Appear at <a href="https://chi2019.acm.org/">CHI 2019: ACM Conference on Human Factors in Computing Systems</a>, <a href="https://arxiv.org/abs/1902.11247">arXiv:1902.11247 [cs.HC]</a></span>
   				  </p> 
				  <p class="phighlight"><a href="https://ai.googleblog.com/2019/04/using-deep-learning-to-improve.html">Google AI Blog</a></p>
   				  <span class="contribution">An approach for modeling and predicting UI quality on tappabiity.
   				  </span>
   		     </div> 
   		     <!-- end of an item -->
			 
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="https://arxiv.org/abs/1810.12406"><img src="images/learn_to_screen.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="https://arxiv.org/abs/1810.12406">Learning to Screen for Fast Softmax Inference on Large Vocabulary Neural Networks</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Patrick H. Chen, Si Si, Sanjiv Kumar, Yang Li, Cho-Jui Hsieh.<span>
				    <span class="conference">To Appear at <a href="https://iclr.cc/Conferences/2019">ICLR'19</a>, <a href="https://arxiv.org/abs/1810.12406">arXiv:1810.12406 [cs.LG]</a></span>
				  </p>
				  <span class="contribution">A novel softmax layer approximation algorithm by exploiting the clustering structure of context vectors.
		     </div> 
		     <!-- end of an item -->
			 
			 <div class="year">
				2018
			 </div>
			 
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="https://arxiv.org/abs/1806.06950"><img src="images/groupreduce.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="https://arxiv.org/abs/1806.06950">GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Patrick H. Chen, Si Si, Yang Li, Ciprian Chelba, Cho-jui Hsieh.<span>
				    <span class="conference">NIPS 2018: <a href="https://arxiv.org/abs/1806.06950">arXiv:1806.06950 [cs.LG]</a></span>
				  </p>
				  <span class="contribution">A method for compressing word embeddings for deep neural language models.
		     </div> 
		     <!-- end of an item -->
			 
 			<!-- start of an item -->
 		     <div style="clear: left; margin: 0 0 1em 0">
 				<!-- thumbnail -->
 				  <a href="https://arxiv.org/abs/1802.07887"><img src="images/online_nonlinear.png" class="thumbnail"/></a>
 				  <p class="ptitle">
 				    <a href="https://arxiv.org/abs/1802.07887">Nonlinear Online Learning with Adaptive Nystr√∂m Approximation</a>
 				  </p>
 				  <p style="margin: 0 0 0.2em 0">
 				    <span class="author">Si Si, Sanjiv Kumar, Yang Li.<span>
 				    <span class="conference"><a href="https://arxiv.org/abs/1802.07887">arXiv:1802.07887 [cs.LG]</a></span>
 				  </p>
 				  <span class="contribution">Adaptively modify the landmark points via online kmeans for kernel approximation and adjust the model accordingly via solving least square problem.
 				  </span>
 		     </div>
			 
			 
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="."><img src="images/tdrnn.png" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="https://arxiv.org/abs/1708.00065">Time-Dependent Representation for Neural Event Sequence Prediction</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Nan Du, Samy Bengio.<span>
				    <span class="conference"><a href="https://iclr.cc/">ICLR'18</a> Workshop Track, <a href="https://arxiv.org/abs/1708.00065">arXiv:1708.00065 [cs.LG]</a></span>
				  </p>
				  <span class="contribution">Introduced two time-dependent event representations and two time-based regularization methods for RNN concerning continuous time.
				  </span>
		     </div> 
			 
 			 <!-- start of an item -->
 		     <div style="clear: left; margin: 0 0 1em 0">
 				<!-- thumbnail -->
 				  <a href="."><img src="images/deepmenu.gif" class="thumbnail"/></a>
 				  <p class="ptitle">
 				    <a href=".">Predicting Human Performance in Vertical Menu Selection Using Deep Learning</a>
 				  </p>
 				  <p style="margin: 0 0 0.2em 0">
 				    <span class="author">Yang Li, Samy Bengio, Gilles Bailly.<span>
 				    <span class="conference">CHI 2018: ACM Conference on Human Factors in Computing Systems.</span>
 				  </p>
 				  <span class="contribution">Presents a deep neural net to model and predict human performance in performing a sequence of UI tasks.
 		     </div> 
 		     <!-- end of an item -->
			 
  			<!-- start of an item -->
  		     <div style="clear: left; margin: 0 0 1em 0" id="pfeuffer_chi18">
  				<!-- thumbnail -->
  				  <a href="."><img src="images/grid.gif" class="thumbnail"/></a>
  				  <p class="ptitle">
  				    <a href=".">Analysis and Modeling of Grid Performance on Touchscreen Mobile Devices</a>
  				  </p>
  				  <p style="margin: 0 0 0.2em 0">
  				    <span class="author">Ken Pfeuffer, Yang Li.<span>
  				    <span class="conference">CHI 2018: ACM Conference on Human Factors in Computing Systems.</span>
  				  </p>
  				  <span class="contribution">Devised a predictive model for human performance on 2D grids using both analytical and machine learning methods.
  		     </div> 
  		     <!-- end of an item -->
			 
 			<!-- start of an item -->
 		     <div style="clear: left; margin: 0 0 1em 0" id="m3">
 				<!-- thumbnail -->
 				  <a href="."><img src="images/m32.gif" class="thumbnail"/></a>
 				  <p class="ptitle">
 				    <a href=".">M3 Gesture Menu: Design and Experimental Analyses of Marking Menus for Touchscreen Mobile Interaction</a>
 				  </p>
 				  <p style="margin: 0 0 0.2em 0">
 				    <span class="author">Jingjie Zheng, Xiaojun Bi, Kun Li, Yang Li, Shumin Zhai.<span>
 				    <span class="conference">CHI 2018: ACM Conference on Human Factors in Computing Systems.</span>
 				  </p>
 				  <span class="contribution">A variant of the marking menu allowing a constant and stationary space use.
 		     </div> 
 		     <!-- end of an item -->
			 
 			<!-- start of an item -->
 		     <div style="clear: left; margin: 0 0 1em 0" id="doppio">
 				<!-- thumbnail -->
 				  <a href="."><img src="images/doppio.gif" class="thumbnail"/></a>
 				  <p class="ptitle">
 				    <a href=".">Doppio: Tracking UI Flows and Code Changes for App Development</a>
 				  </p>
 				  <p style="margin: 0 0 0.2em 0">
 				    <span class="author">Peggy Chi, Sen-po Hu, Yang Li.<span>
 				    <span class="conference">CHI 2018: ACM Conference on Human Factors in Computing Systems.</span>
 				  </p>
 				  <span class="contribution">Generates video illustration of UI behavior for code snippet from execution.
 				  </span>
 		     </div> 
 		     <!-- end of an item -->
			 
		 <div class="year">
			2017
		 </div>
		 
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0" id="biplab_uist17_1">
				<!-- thumbnail -->
				  <a href="."><img src="images/zipt.png" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">ZIPT: Zero-Integration Performance Testing of Mobile App Designs</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Biplab Deka, Zifeng Huang, Chad Franzen, Jeffrey Nichols, Yang Li, Ranjitha Kumar.<span>
				    <span class="conference">UIST'17: ACM Symposium on User Interface Software and Technology, 2017.</span>
				  </p>
				  <span class="contribution">Low-overhead collection of performance data for mobile app designs using crowdsourcing.
				  </span>
		     </div> 
			 
 			<!-- start of an item -->
 		     <div style="clear: left; margin: 0 0 1em 0" id="biplab_uist17_2">
 				<!-- thumbnail -->
 				  <a href="."><img src="images/rico.png" class="thumbnail"/></a>
 				  <p class="ptitle">
 				    <a href=".">RICO: A Mobile App Dataset for Building Data-Driven Design Applications</a>
 				  </p>
 				  <p style="margin: 0 0 0.2em 0">
 				    <span class="author">Biplab Deka, Zifeng Huang, Chad Franzen, Joshua Hibschman, Daniel Afergan, Yang Li, Jeffrey Nichols, Ranjitha Kumar.<span>
 				    <span class="conference">UIST'17: ACM Symposium on User Interface Software and Technology, 2017.</span>
 				  </p>
 				  <span class="contribution">Harvesting a dataset for advancing data-driven design of mobile apps from over 9.7K existing Android apps using a
combination of human and automated crawling of apps.
 				  </span>
 		     </div>

			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0" id="improv">
				<!-- thumbnail -->
				  <a href="."><img src="images/improv.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">Improv: An Input Framework for Improvising Cross-Device Interaction By Demonstration</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Xiang 'Anthony' Chen, Yang Li.<span>
				    <span class="conference">TOCHI: ACM Transactions on Computer-Human Interaction, 2017.</span>
				  </p>
				  <span class="contribution">Compose cross-device input by examples based on DOF of target interaction behavior.
				  </span>
		     </div> 
		     <!-- end of an item -->
			 
			 <div class="year">
				2016
			 </div>
			
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0" id="body">
				<!-- thumbnail -->
				  <a href="."><img src="images/bodytap.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">Bootstrapping User-Defined Body Tapping Recognition with Offline-Learned Probabilistic Representation</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Xiang 'Anthony' Chen, Yang Li.<span>
				    <span class="conference">UIST 2016: ACM Symposium on User Interface Software and Technology.</span>
				  </p>
				  <span class="contribution">Recognize motion gestures by combining offline learned representation and templated-based online learing.
				  </span>
		     </div> 
		     <!-- end of an item -->
			 
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0" id="morpher">
				<!-- thumbnail -->
				  <a href="."><img src="images/morphor.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">Gesture Morpher: Video-Based Retargeting of Multi-Touch Interactions</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Ramik Sadana, Yang Li.<span>
				    <span class="conference">MobileHCI 2016: ACM Conference on Human-Computer Interaction with Mobile Devices and Services.</span>
				  </p>
				  <span class="contribution">Enables prototyping and testing multi-touch interactions based on video recordings of target application behaviors, without any programming.
				  </span>
		     </div> 
		     <!-- end of an item -->
			 
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0" id="cross_story">
				<!-- thumbnail -->
				  <a href="."><img src="images/demoscript.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">Enhancing Cross-Device Interaction Scripting with Interactive Illustrations</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Peggy Chi, Yang Li, Bjorn Hartmann.<span>
				    <span class="conference">CHI 2016: ACM Conference on Human Factors in Computing Systems.</span>
  				  <p class="phighlight">
  				    <span style="color: green">Best Paper Award</span>
  				  </p>
				  </p>
				  <span class="contribution">Contributes a cross-device storyboard and interactive illustration mechanisms for scripting.
				  </span>
		     </div> 
		     <!-- end of an item -->
			 
 			<!-- start of an item -->
 		     <div style="clear: left; margin: 0 0 1em 0">
 				<!-- thumbnail -->
 				  <a href="."><img src="images/gesture-audio.gif" class="thumbnail"/></a>
 				  <p class="ptitle">
 				    <a href=".">Using Audio Cues to Support Motion Gesture Interaction on Mobile Devices</a>
 				  </p>
 				  <p style="margin: 0 0 0.2em 0">
 				    <span class="author">Sarah Morrison-Smith, Megan Hofmann, Yang Li, Jaime Ruiz.<span>
 				    <span class="conference">ACM Transactions on Applied Perception, 13(3), May 2016.</span>
 				  </p>
 				  <span class="contribution">Investigates techniques for using audio characteristics to provide feedback on the system interpretation of user motion gesture input.
 				  </span>
 		     </div> 
 		     <!-- end of an item -->
			 
			 <div class="year">
				2015
			 </div>
			 
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0" id="weave">
				<!-- thumbnail -->
				  <a href="."><img src="images/weave.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">Weave: Scripting Cross-Device Wearable Interaction</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Peggy Chi, Yang Li.<span>
				    <span class="conference">CHI 2015: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <span class="contribution">Provides a set of high-level APIs, based on JavaScript, and integrated tool support
					for developers to easily distribute UI output and combine user input and sensing events across devices for cross-device interaction.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="."><img src="images/gesture-on.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">Gesture On: Always-On Touch Gestures for Fast Mobile Access from Device Standby Mode</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Hao Lu, Yang Li.<span>
				    <span class="conference">CHI 2015: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <span class="contribution">Contributes a system that overrides the mobile platform kernel behavior to 
					enable touchscreen gesture shortcuts in standby mode. A user can issue a gesture on the touchscreen 
					before the screen is even turned on.
				  </span>
		     </div> 
		     <!-- end of an item -->
			
			 <div class="year">
				2014
			 </div>
			
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="http://dl.acm.org/citation.cfm?id=2631914"><img src="images/touch.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="http://dl.acm.org/citation.cfm?id=2631914">Optimistic Programming of Touch Interaction</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Hao Lu, Haimo Zhang.<span>
				    <span class="conference">TOCHI: ACM Transactions on Computer-Human Interaction, 2014.</span>
				  </p>
				  <span class="contribution">Integrated tool and inference support that allows developers to easily create touch behaviors in their apps. 
				  </span>
		    </div> 
		    <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="http://dl.acm.org/citation.cfm?id=2647355"><img src="images/reflection.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="http://dl.acm.org/citation.cfm?id=2647355">
						Reflection: Enabling Event Prediction As an On-Device Service for Mobile Interaction</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li.<span>
				    <span class="conference">UIST 2014: ACM Symposium on User Interface Software and Technology.</span>
				  </p>
				  <span class="contribution">An on-device infrastructure that provides event prediction 
					as a service to mobile applications. 
				  </span>
		    </div> 
		    <!-- end of an item -->
			
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="http://dl.acm.org/citation.cfm?id=2647363"><img src="images/sidetap.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="http://dl.acm.org/citation.cfm?id=2647363">
					Detecting Tapping Motion on the Side of Mobile Devices By Probabilistically Combining Hand Postures</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">William McGrath, Yang Li.<span>
				    <span class="conference">UIST 2014: ACM Symposium on User Interface Software and Technology.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/z0gVdp4LY1Q">Video</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				  </p>
				  <span class="contribution">A method for detecting finger taps on the different sides of a smartphone, 
					using the built-in motion sensors of the device. 
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="http://dl.acm.org/citation.cfm?id=2659766"><img src="images/hobs.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="http://www.cs.berkeley.edu/~bjoern/papers/zhang-hobs-sui2014.pdf">
					HOBS: Head Orientation-Based Selection in Physical Spaces</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Ben Zhang, Yu-Hsiang Chen, Claire Tuna, Achal Dave, Yang Li, Edward Lee, Bjorn Hartmann.<span>
				    <span class="conference">SUI'2014: ACM Symposium on Spatial User Interaction.</span>
				  </p>
				  <span class="contribution">Presented the iterative design and evaluation of a head orientation-based selection technique, 
	                which augments Google Glass with an infrared (IR) emitter for selecting IR-equipped smart appliances at a distance. 
	                (acceptance rate: 29%)
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="http://dl.acm.org/citation.cfm?id=2598195"><img src="images/gesturemote.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="http://dl.acm.org/citation.cfm?id=2598195">Gesturemote: interacting with remote displays through touch gestures</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Hao Lu, Matei Negulescu, Yang Li.<span>
				    <span class="conference">AVI 2014: International Working Conference on Advanced Visual Interfaces.</span>
				  </p>
				  <span class="contribution">A technique for interacting with remote displays through touch gestures on a handheld touch surface,
					which supports a wide range of interaction behaviors, from low pixel-level interaction such as pointing, 
					to medium-level interaction such as structured navigation, 
					to high-level interaction such as shortcuts.
				  </span>
		     </div> 
		     <!-- end of an item -->
			
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/gscript.pdf"><img src="images/gscript.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/gscript.pdf">Gesture Script: Recognizing Gestures and their Structure using Rendering Scripts and Interactively Trained Parts</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Hao Lu, James Fogarty, Yang Li.<span>
				    <span class="conference">CHI 2014: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/5FvhcmzeNe8">Video</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				    <span style="color: green">Best Paper Honorable Mention Award</span>
				  </p>
				  <span class="contribution">Recognizing gestures and their properties using examples and parts-based scripting. 
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/inkanchor.pdf"><img src="images/inkanchor.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/inkanchor.pdf">InkAnchor: Enhancing Informal Ink-Based Note Taking on Touchscreen Mobile Phones</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yi Ren, Yang Li, Edward Lank.<span>
				    <span class="conference">CHI 2014: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/YiRjyAi_HH0">Video</a>
				  </p>
				  <span class="contribution">Presented a tool for informal note-taking on the touchscreen by sketching. 
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/gestkeyboard.pdf"><img src="images/gestkeyboard.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/gestkeyboard.pdf">GestKeyboard: Enabling Gesture-Based Interaction on Ordinary Physical Keyboard</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Haimo Zhang, Yang Li.<span>
				    <span class="conference">CHI 2014: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/D76qt8fUPkw">Video</a>
				  </p>
				  <span class="contribution">Enabled gesturing on an ordinary physical keyboard.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/routemap.pdf"><img src="images/routemap.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/routemap.pdf">Hierarchical Route Maps for Efficient Navigation</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Fangzhou Wang, Yang Li, Daisuke Sakamoto, Takeo Igarashi.<span>
				    <span class="conference">IUI 2014: International Conference on Intelligent User Interfaces.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/QdE5s30buy8">Video</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				    <span style="color: green">Best Paper Award</span>
				  </p>
				  <span class="contribution">Interactive optimization of map routes visualization.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/teachmotion.pdf"><img src="images/teachmotion.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/teachmotion.pdf">Teaching Motion Gestures via Recognizer Feedback</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Ankit Kamal, Yang Li, Edward Lank.<span>
				    <span class="conference">IUI 2014: International Conference on Intelligent User Interfaces.</span>
				  </p>
				  <span class="contribution">Explored mechanisms to teach end users motion gestures.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			 <div class="year">
				2013
			 </div>
			
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/crowdlearner.pdf"><img src="images/crowdlearner.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/crowdlearner.pdf">CrowdLearner: Rapidly Creating Mobile Recognizers Using Crowdsourcing</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Shahriyar Amini, Yang Li.<span>
				    <span class="conference">UIST 2013: ACM Symposium on User Interface Software and Technology.</span>
				  </p>
				  <span class="contribution">Presented a crowdsourcing platform for automatically generating recognizers that leverage built-in sensors on mobile devices,
					e.g., paying $10 for creating a usable stroke gesture recognizer in a few hours.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/openproject.pdf"><img src="images/openproject.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/openproject.pdf">Open Project: A Lightweight Framework for Remote Sharing of Mobile Applications</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Matei Negulescu, Yang Li.<span>
				    <span class="conference">UIST 2013: ACM Symposium on User Interface Software and Technology.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/w286qmNVBFc">Video</a>
				  </p>
				  <span class="contribution">Discussed an end-to-end framework that allows a user to project a native mobile application onto 
					a display using a phone camera. Any display can become projectable instantaneously by accessing the Open Project web service.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/gstudio.pdf"><img src="images/gstudio.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/gstudio.pdf">Gesture Studio: Authoring Multi-Touch Interactions through Demonstration and Composition</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Hao Lu, Yang Li.<span>
				    <span class="conference">CHI 2013: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <span class="contribution">Presented a tool that combines programming by demonstration and declaration, via a video-editing
					metaphor for creating multi-touch interaction.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			<!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/ffits.pdf"><img src="images/ffitts.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/ffits.pdf">FFitts Law: Modeling Finger Touch With Fitts Law</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Xiaojun Bi, Yang Li, Shumin Zhai.<span>
				    <span class="conference">CHI 2013: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <span class="contribution">Proposed and experimented with a new model that extends Fitts' law with a dual-Gaussian 
					distribution for modeling finger touch behaviors.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			 <div class="year">
				2012
			 </div>
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/avi-2012-keynote.pdf"><img src="images/avi-2012-keynote.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/avi-2012-keynote.pdf">Gesture-Based Interaction: A New Dimension for Mobile User Interfaces</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li.<span>
				    <span class="conference">Invited Keynote at AVI 2012: International Working Conference on Advanced Visual Interfaces.</span>
				  </p>
				  <p class="phighlight">
				    <a href="talks/yang-li-avi-2012.pptx">Talk</a>
				  </p>
				  <span class="contribution">Investigated various aspects of gesture-based interaction on mobile devices, including gesture-based applications,
					recognition and tools for creating gesture-based behaviors.
				  </span>
		     </div> 
		     <!-- end of an item -->
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/gcoder.pdf"><img src="images/gcoder.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/gcoder.pdf">Gesture Coder: A Tool for Programming Multi-Touch Gestures by Demonstration</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Hao Lu, Yang Li.<span>
				    <span class="conference">CHI 2012: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/8OXExn29OTE">Video</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				    <span style="color: green">Best Paper Honorable Mention Award</span>
				  </p>
				  <span class="contribution">Present a tool that automatically generates code for recognizing each state of 
					multi-touch gestures and invoking corresponding application actions, based on a few gesture examples given by the developer.
				  </span>
		     </div> 
		     <!-- end of an item -->
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/gmark.pdf"><img src="images/gmark.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/gmark.pdf">Bootstrapping Personal Gesture Shortcuts with the Wisdom of the Crowd and Handwriting Recognition</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Tom Ouyang, Yang Li.<span>
				    <span class="conference">CHI 2012: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/lNfxVEjFMN4">Video</a>
				  </p>
				  <span class="contribution">Contribute the approaches for bootstrapping a user‚Äôs personal gesture library, 
					alleviating the need to define most gestures manually.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="."><img src="images/appsearch.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href=".">Gesture Search: Random Access to Smartphone Content</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li.<span>
				    <span class="conference">Invited article for IEEE Computer: Pervasive Computing.</span>
				  </p>
				  <span class="contribution">Present a tool for random access of smartphone content by drawing touchscreen gestures.
					It flattens the UI hierarchy of smartphone interfaces.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="./pdf/avi12.pdf"><img src="images/avimotion.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="./pdf/avi12.pdf">Tap, Swipe, or Move: Attentional Demands for Distracted Smartphone Input</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Negulescu, M., Ruiz, J., Li, Y. and Lank, E..<span>
				    <span class="conference">AVI 2012: International Working Conference on Advanced Visual Interfaces.</span>
				  </p>
				  <span class="contribution">Investigated attention demands of motion gestures in comparison with traditional interaction techniques for mobile devices.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
			 <div class="year">
				2011
			 </div>
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href=""><img src="images/gestureavatar.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/gestureavatar-chi2011.pdf">Gesture Avatar: A Technique for Operating Mobile User Interfaces Using Gestures</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Hao Lu, Yang Li.<span>
				    <span class="conference">CHI 2011: ACM Conference on Human Factors in Computing Systems.</span>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/HLK3YB3wsUg">Video</a>
				  </p>
				  <span class="contribution">Present Gesture Avatar, a novel interaction technique that allows users to operate 
					existing arbitrary user interfaces using gestures. It leverages the visibility of graphical user interfaces 
					and the casual interaction of gestures. It outperformed prior techniques especially while users are on the go.</span>
		     </div> 
		     <!-- end of an item -->
			 
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href=""><img src="images/deepshot.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/deepshot-chi2011.pdf">Deep Shot: A Framework for Migrating Tasks Across Devices Using Mobile Phone Cameras</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Tsung-Hsiang Chang, Yang Li.<span>
				    <span class="conference">CHI 2011: ACM Conference on Human Factors in Computing Systems.</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/JJSZGdMYV9s">Video</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://googleresearch.blogspot.com/2011/07/what-you-capture-is-what-you-get-new.html">Blog</a>
				  </p>
				  <span class="contribution">Presents a framework for migrating tasks across devices using mobile cameras. It supports two interaction techniques,
					Deep Shot and Posting, that enabled direct manipulation of information and work states in a multi-device environment.</span>
		     </div> 
		     <!-- end of an item -->
		
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href=""><img src="images/doubleflip.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/doubleflip-chi2011.pdf">DoubleFlip: A Motion Gesture Delimiter for Mobile Interaction</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Jaime Ruiz, Yang Li.<span>
				    <span class="conference">CHI 2011: ACM Conference on Human Factors in Computing Systems.</span><br/>
				  </p>
				  <span class="contribution">Designed a motion gesture for separating intended motion input from ambient motion of mobile phones. A DTW-based
					recognizer was built to recognize the gesture which had high precision and recall.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href=""><img src="images/motiongesture.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/motiongestures-chi2011.pdf">User-Defined Motion Gestures for Mobile Interaction</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Jaime Ruiz, Yang Li, Edward Lank.<span>
				    <span class="conference">CHI 2011: ACM Conference on Human Factors in Computing Systems.</span><br/>
				  </p>
				  <span class="contribution">Present the results of a guessability study that elicits end-user motion gestures to invoke commands on a 
					smartphone device, which led to the design of a taxonomy for motion gestures and an end-user inspired motion gesture set.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href=""><img src="images/gesturestudy.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/gesturestudy-chi2011.pdf">Experimental Analysis of Touch-Screen Gesture Designs in Mobile Environments</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Andrew Bragdon, Eugene Nelson, Yang Li, Ken Hinckley.<span>
				    <span class="conference">CHI 2011: ACM Conference on Human Factors in Computing Systems.</span><br/>
				  </p>
				  <span class="contribution">Investigates the impact of situational impairments on touchscreen interaction. Reveals that in the presence 
					of environmental distractions, gestures can offer significant performance gains and reduced attentional load, while performing just 
					as well as soft buttons when the user's attention is fully focused on the phone.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
		     <div class="year">
				2010
			 </div>
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/gesturesearch-uist2010.pdf"><img src="images/gsearch.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/gesturesearch-uist2010.pdf">Gesture Search: A Tool for Fast Mobile Data Access</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li.<span>
				    <span class="conference">UIST 2010: ACM Symposium on User Interface Software and Technology. p87-96.</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="https://play.google.com/store/apps/details?id=com.google.android.apps.gesturesearch&hl=en/">Available on Google Play!</a>
				  </p>
				  <span class="contribution">Describes a tool that allows users to access mobile phone data using touch screen gestures. Gesture Search
					flattens the deep UI hierarchy of mobile user interfaces and learns the mapping from gestures to data items.</span>
		     </div> 
		     <!-- end of an item -->
		     
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/framewire-chi2010.pdf"><img src="images/framewire.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/framewire-chi2010.pdf">FrameWire: A Tool for Automatically Extracting Interaction Logic from Paper Prototyping Tests</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Xiang Cao, Katherine Everitt, Morgan Dixon, James Landay.<span>
				    <span class="conference">CHI 2010: ACM Conference on Human Factors in Computing Systems. p.503-512.</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="http://youtu.be/WgMTYsZ5WuI">Video</a>
				  </p>
				  <span class="contribution">Presents a tool for automatically extracting interaction logic from the video recording of paper prototype
					tests. FrameWire generates interactive prototypes from extracted interaction logic.</span>
		     </div> 
		     <!-- end of an item -->
		
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/protractor-chi2010.pdf"><img src="images/protractor.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/protractor-chi2010.pdf">Protractor: A Fast and Accurate Gesture Recognizer</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li.<span>
				    <span class="conference">CHI 2010: ACM Conference on Human Factors in Computing Systems. p.2169-2172.</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="protractor/">Pseudo Code</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://android.googlesource.com/platform/frameworks/base/+/master/core/java/android/gesture/GestureUtils.java">
					Java implementation in the Android core framework</a>
				  </p>
				  <span class="contribution">Presents an algorithm for recognizing drawn gestures. Protractor employs a closed-form
					solution to find the best match of an unknown gesture given a set of templates.</span>
		     </div> 
		     <!-- end of an item -->
		
		     <div class="year">
				2009
			 </div>
			
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/gesturelibrary-ieee2009.pdf"><img src="images/gesturelibrary.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/gesturelibrary-ieee2009.pdf">Beyond Pinch and Flick: Enriching Mobile Gesture Interaction</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li.<span>
				    <span class="conference">IEEE Computer: Invisible Computing, December 2009.</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="http://android-developers.blogspot.com/2009/10/gestures-on-android-16.html">Shipped to the Android SDK</a>
				  </p>
				  <span class="contribution">Presents the design of a toolkit for gesture-based interaction for touchscreen mobile phones.
					Introduces the concept of gesture overlays.
				  </span>
		     </div> 
		     <!-- end of an item -->
			
			 <div class="year">
				2008
			 </div>
			
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/activitydesigner-chi2008.pdf"><img src="images/adesigner.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/activitydesigner-chi2008.pdf">ActivityDesigner: Activity-Centric Prototyping of Ubicomp Applications for Long-Lived, Everyday Activities</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, James Landay.<span>
				    <span class="conference">CHI 2008: ACM Conference on Human Factors in Computing Systems. p.1303-1312.</span><br/>
				  </p>
				  <p class="phighlight">
				    <span style="color: green">Best Paper Honorable Mention Award</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				    <a href="http://youtu.be/Hg2Ca2Eqgi0">Video</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://activitystudio.sourceforge.net/">Download</a>
				  </p>
				  <span class="contribution">Presents a tool that allows designers to incorporate large-scale, long-term human activities as a basis for design, and speeds up ubicomp design by providing integrated support for modeling, prototyping, deployment and in situ testing.</span>
		     </div> 
		     <!-- end of an item -->
		
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/cascadia-mobisys2008.pdf"><img src="images/cascadia.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/cascadia-mobisys2008.pdf">Cascadia: A System for Specifying, Detecting, and Managing RFID Events</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Evan Welbourne, Nodira Khoussainova, Julie Letchner, Yang Li, Magdalena Balazinska,
					Gaetano Borriello, Dan Suciu.<span>
				    <span class="conference">MobiSys 2008: The International Conference on Mobile Systems, Applications, and Services. p.281-294.</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="http://rfid.cs.washington.edu/index.html">Project Website</a>
				  </p>
				  <span class="contribution">Cascadia is a system that provides RFID-based pervasive computing applications with an infrastructure for specifying, extracting and managing meaningful high-level events from raw RFID data.</span>
		     </div> 
		     <!-- end of an item -->
		
		     <div class="year">
				2007
			 </div>
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/locationwoz-ieee2007.pdf"><img src="images/woz.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/locationwoz-ieee2007.pdf">Design Challenges and Principles for Wizard of Oz Testing of Ubicomp Applications</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Jason Hong, James Landay.<span>
				    <span class="conference">IEEE Pervasive Computing, April-June, 2007, 6(2): 70-75.</span><br/>
				  </p>
				  <span class="contribution">Presents the $1 algorithm for gesture recognition and a comprehensive study that evaluates $1 against
					two other popular gesture recognition algorithms: Dynamic Time Wrapping and Rubine Recognizer. The study indicated that the $1
					recognizer though simple outperformed its peers in both accuracy and learnability.
				  </span>
		     </div> 
		     <!-- end of an item -->
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/onedollar-uist2007.pdf"><img src="images/1dollar.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/onedollar-uist2007.pdf">Gestures without libraries, toolkits or Training: a $1.00 Recognizer for User Interface Prototypes</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Jacob Wobbrock, Andy Wilson, Yang Li.<span>
				    <span class="conference">UIST 2007: ACM Symposium on User Interface Software and Technology. p.159-168.</span><br/>
				  </p>
				  <p class="phighlight">
					<span style="color: green">Invited to the SIGGRAPH UIST Reprise Session</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				  </p>
				  <span class="contribution">Presents the $1 algorithm for gesture recognition and a comprehensive study that evaluates $1 against
					two other popular gesture recognition algorithms: Dynamic Time Wrapping and Rubine Recognizer. The study indicated that the $1
					recognizer though simple outperformed its peers in both accuracy and learnability.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/brickroad-chi2007.pdf"><img src="images/brickroad.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/brickroad-chi2007.pdf">BrickRoad: A Light-Weight Tool for Spontaneous Design of Location-Enhanced Applications</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Alan Liu, Yang Li.<span>
				    <span class="conference">CHI 2007: ACM Conference on Human Factors in Computing Systems: pp.295-298.</span><br/>
				  </p>
				  <span class="contribution">Presents a tool for testing location-based behaviors without specifying interaction logic. The tool explores
					the extreme of Wizard of Oz approaches for designing field-oriented applications, i.e., testing with zero effort beforehand.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
		     <div class="year">
				2006
			 </div>
		
		     <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/locationwoz-chi2006.pdf"><img src="images/locationtracking.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/locationwoz-chi2006.pdf">Design and Experimental Analysis of Continuous Location Tracking Techniques for Wizard of Oz Testing</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Evan Welbourne, James Landay.<span>
				    <span class="conference">CHI 2006: ACM Conference on Human Factors in Computing Systems: pp.1019-1022.</span><br/>
				  </p>
				  <span class="contribution">Presents various Wizard of Oz techniques for continuously tracking user locations.
				  </span>
		     </div> 
		     <!-- end of an item -->
		
		     <div class="year">
				2005
			 </div>
			
             <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/monet-uist2005.pdf"><img src="images/monet.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/monet-uist2005.pdf">Informal Prototyping of Continuous Graphical Interactions by Demonstration</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, James Landay.<span>
				    <span class="conference">UIST 2005: ACM Symposium on User Interface Software and Technology. p.221-230.</span><br/>
				  </p>
				  <p class="phighlight">
					<span style="color: green">Invited to the SIGGRAPH UIST Reprise Session</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
					<a href="http://youtu.be/X9sjLrTHDes">Video</a>
				  </p>
				  <span class="contribution">Presents a tool for creating continuous interactions using examples. Discusses the algorithms
					for learning continuous interaction behaviors from discrete examples, without using any domain knowledge.
				  </span>
		     </div> 
		     <!-- end of an item -->
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/modeswitch-chi2005.pdf"><img src="images/modeswitch.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/modeswitch-chi2005.pdf">Experimental Analysis of Mode Switching Techniques in Pen-based User Interfaces</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Ken Hinckley, Zhiwei Guan, James Landay.<span>
				    <span class="conference">CHI 2005: ACM Conference on Human Factors in Computing Systems. p.461-470</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="images/modeswitch_demo.gif">Experimental Software Demo</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				  </p>
				  <span class="contribution">Conducted a study to compare different mode switching techniques for pen-based user interfaces. The
					study revealed that bi-manual based mode switching outperformed other techniques.</span>
		     </div> 
		     <!-- end of an item -->
		
		     <div class="year">
				2004
			 </div>
			
			 <!-- start of an item -->
		     <div style="clear: left; margin: 0 0 1em 0">
				<!-- thumbnail -->
				  <a href="pdf/topiary-uist2004.pdf"><img src="images/topiary.gif" class="thumbnail"/></a>
				  <p class="ptitle">
				    <a href="pdf/topiary-uist2004.pdf">Topiary: A Tool for Prototyping Location-Enhanced Applications</a>
				  </p>
				  <p style="margin: 0 0 0.2em 0">
				    <span class="author">Yang Li, Jason Hong, James Landay.<span>
				    <span class="conference">UIST 2004: ACM Symposium on User Interface Software and Technology: CHI Letters, 6(2): p.217-226.</span><br/>
				  </p>
				  <p class="phighlight">
				    <a href="http://dub.washington.edu/topiary/download">Download</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				    <a href="http://youtu.be/4tCxAJJ9_NI">Video</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				    <a href="http://dub.washington.edu/topiary/examples">Examples</a>
				  </p>
				  <span class="contribution">Topiary is a tool for rapidly prototyping location-based applications. 
					It introduces a Wizard of Oz approach for testing location-based applications in the field, without requiring a location infrastructure.</span>
		     </div> 
		
		     <!-- end of an item -->
		   

		 </div> <!-- left content end -->
